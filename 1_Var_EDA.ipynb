{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Revisit the Property Assessment data. We are looking for some info on home prices - we want to narrow our search to a specific subset of homes.\n",
    "\n",
    "Our hypothesis is that over time, prices in Edmonton will rise. If we can invest in a segment of the market that is undervalued, that segment will rise faster as it \"catches up\" with the rest. We don't know if this hypothesis is true in reality - in the future we could do some predictive modelling to try to test it. We are going with a HIPPO opinion - low valued segments will rise, so that is what we will look for in our data. \n",
    "\n",
    "We also are smaller investors. We don't have the up front cash to purchase big money properties and \"swing for the fences\", we would very much prefer to target properties that are relatively less expensive, to allow us to purchase more and diversify the risk. \n",
    "\n",
    "So, our goal is to identify which segments of real estate have values that are suitable for investment, based on our assumptions.  \n",
    "(Note: There are differnt potential answers - I find a set of homes that may look good based on our criteria, there's probably others, it is not a yes/no answer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use: Attempt to break down and examine the data to find some property groups that appear to be solid investments, supported by the data you have. You can follow my example, or go your own way. There's probably many potential groups that make sense. The solution version has everything I did. Feel free to add more code blocks. I chopped them down so there are not a tonne of empty ones. As well, the exploration is somewhat open ended. If you want to closely follow along my steps, that's fine. You could do things differently, or in a somewhat different order, and that would be all good too. If you feel very comfortable doing things on your own, it is \"better\" practice to follow less closely. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import thinkplot\n",
    "import thinkstats2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#These 3 things allow for some prettier graphs, using a different visualization package - seaborn.\n",
    "#This isn't required, we'll start using this a little bit as we go. Seaborn's big selling point\n",
    "#is that it allows us to create many common graphs, that are very nice, relatively easily\n",
    "#The third line just makes the default plot size larger, you can change the numbers if you want. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Example of a seaborn distpolot - a histogram with a PDF overlayed on it. I use it in the solution.\n",
    "#In this example, the data is the first argument, the other two arguments are sets of \"customizations\" for the histogram and PDF (KDE) part.\n",
    "#You can use this, if you want, just change the data, and the labels and it should be usable for everything here.\n",
    "#There are more options and examples detailed here: https://seaborn.pydata.org/generated/seaborn.distplot.html\n",
    "\n",
    "#sns.distplot(dtGlen[\"Assessed Value\"], hist_kws={\"label\":\"Condos\"}, kde_kws={\"label\":\"Condo PDF\"},)\n",
    "#sns.distplot(glen[\"Assessed Value\"], hist_kws={\"label\":\"Glenora Garage\"}, kde_kws={\"label\":\"Glenora Garage PDF\"},)\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#This function does the same work as the one we made last time - it does 6 graphs all in bulk: Hist, PMF, CDF, PDF, normal and lognormal prob plots. \n",
    "#One addition is the rnd=0 thing. That's how we can make one of those optional paramaters, if you don't provide anything there, the hist will have no\n",
    "#rounding; if you provide a number, the histogram will round to that many digits. \n",
    "def bigGraph(df_in, columnName, rnd=0):\n",
    "    data = pd.Series(df_in[columnName])\n",
    "    hist = thinkstats2.Hist(round(data, rnd))\n",
    "    pmf = thinkstats2.Pmf(data)\n",
    "    cdf = thinkstats2.Cdf(data)\n",
    "    thinkplot.PrePlot(6, rows =2, cols=3)\n",
    "    thinkplot.Hist(hist)\n",
    "    thinkplot.SubPlot(2)\n",
    "    thinkplot.Pmf(pmf)\n",
    "    thinkplot.SubPlot(3)\n",
    "    thinkplot.Cdf(cdf)\n",
    "    thinkplot.SubPlot(4)\n",
    "    thinkstats2.NormalProbabilityPlot(data)\n",
    "    thinkplot.SubPlot(5)\n",
    "    thinkstats2.NormalProbabilityPlot(np.log(data))\n",
    "    thinkplot.SubPlot(6)\n",
    "    pdf = thinkstats2.EstimatedPdf(data)\n",
    "    thinkplot.Pdf(pdf)\n",
    "    thinkplot.Config()\n",
    "    return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Load data - I used the odd varaible name because I want the final name to be \"df\" after I do any filtering, so it is easier. \n",
    "df_init = pd.read_csv(\"Assessments.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "START HERE!\n",
    "\n",
    "Part 1: Preview data and make sure the data present is what we want/need. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Examine the data a little bit to see what we have. \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are looking for houses. There's a bunch of data here for houses that are both insanely cheap - near 0, or insanely expensive. We aren't big money investors, so I think the properties over $1mill are not relevant to our examination. \n",
    "\n",
    "We don't want that stuff because, for our purposes, it isn't usefull, so we'll remove it - leaving us with only homes that cost a \"normal\" amount. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Filter out houses that are out of the range that we care about.\n",
    "#I used under $50k or over $1mill - this decision is largely arbitrary, based on what we are actually (pretending) to use this data for. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "About 50,000 properties removed. Seems reasonable. We can look at the distribution and see what is there...\n",
    "\n",
    "You could use our original graphing techniques (thinkplot), the bigGraph function above, the seaborn plotting, or a combination of all. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create some plots to examine the distribution of the data. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have taken a look at the statistics and the distribution of the data. Can we draw any conclusions from what we've seen here? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 2: Split the data, to look for tendencies by groups. We have several values we can use, I will start with the most simple - garage. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Split the data into subsets. I used garage/not for my subsets. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plot the subsets to look at their individual distributions. \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that both of our slices of data, once separated, are much closer to a normal distribution. Analyzing these two separately is probably going to be easier than the double bump original distribution. \n",
    "I will caclulate a bunch of statistics for each group - including skew, so I can get a measure of how \"stretched out\" the distribution is. \n",
    "\n",
    "I will also look at each group and figure out what share of the homes are less than $200k, $350k, and $500k, for my own info - if I want to invest in properties that are \"lowish\" in value, how many are there?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Example of printing out a bunch of statistics on one line\n",
    "\n",
    "#print(\"Garage - Mean:\", df_gar[\"Assessed Value\"].mean(), \"Median:\", df_gar[\"Assessed Value\"].median(), \"STD:\", df_gar[\"Assessed Value\"].std(), \"Skew:\", thinkstats2.Skewness(df_gar[\"Assessed Value\"]))\n",
    "#print(\"Non-Garage - Mean:\", df_no[\"Assessed Value\"].mean(), \"Median:\", df_no[\"Assessed Value\"].median(), \"STD:\", df_no[\"Assessed Value\"].std(), \"Skew:\", thinkstats2.Skewness(df_no[\"Assessed Value\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Use CDF to figure out how many are under each value cutoff. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What can we make of this? A few things, we aren't entirely sure if they will be important right now.\n",
    "\n",
    "- Non garage houses are about $200k cheaper on average.\n",
    "\n",
    "- Non garage houses are more tightly packed (smaller std), more \"peaky\" (kurtosis), and trail off to the right more (skew). This should kind of make sense logically, there's lots of smaller and cheaper nonm-garage homes, then there are a handful of luxury properties that scatter around the higher values. We can hypothesize that many/most non-garage houses are condos, but we need to check it. Houses over a certain, relatively low, value tend to always have garages so there's less weirdness to the distribution. \n",
    "\n",
    "- There is a comparatively massive cache of non-garage homes that are under $200k, and almost all are under $350k"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Use suite values to assess house/condo split. My assumption is that if a home has a Suite number, it is a condo; if it doesn't, it is a house.\n",
    "#If I calculate that percentage for each group, it could help indicate if my guess is true:\n",
    "\n",
    "#Example of calculating how many of each set have no suite number. \n",
    "#print(\"Garage:\", df_gar[\"Suite\"].isnull().sum()/len(df_gar[\"Suite\"]))\n",
    "#print(\"Non:\", df_no[\"Suite\"].isnull().sum()/len(df_no[\"Suite\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Graph the suite/nonsuite groups against eachother. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think my hypothesis is supported - non garage houses mostly do have a suite number, garage ones mainly don't. This isn't a 100% definitive result, but it is pretty solid. \n",
    "\n",
    "What can we take from this? Condos are cheaper, houses are more expensive. Garage is an OK-ish proxy for the house/condo split, not at all perfect - I also suspect it is probably a stronger relationship as prices rise, I doubt many expensive houses don't have garages. \n",
    "\n",
    "As well, perhaps as the city grows and as it becomes more dense and urban, perhaps the value of condos will rise and become closer to homes. We see a pattern of central condos becomming more expensive in most larger cities, a hypothesis that a similar thing will happen here is pretty reasonable. \n",
    "\n",
    "\n",
    "NOTE: At this point, we could also/alternatively split the data into suite/non-suite segments, or a 4 way split with both suite and garage. I will continue with garage/non for now. In real life, there's a pretty high probability that we'd come back and also split the data by suite. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 4: Investigate location. \n",
    "\n",
    "To investigate this more, we need to take a look at where these properties are located.... We can see what data we have - Ward, neighborhood, and lat/lon all indicate position. I need to go look at a map to see what is useful. Wards are large, and there are 12 of them. Neigborhoods are small, and there are a lot. We can start with wards and do a crude split for initial investigation. \n",
    "\n",
    "Note: We'd probably want to investigate things like square footage at this point in real life. We'll look at that comming up soon - looking at how two variables are related (correlated) to each other. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#How many properties are in each ward? "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On a map, Ward 6 is downtown, it has the most non garage properties, which makes sense. 9 is Riverbend, there's lots of condos in Terwilligar and area. 4 is the far north east, 1 is the north-west, 11 is near south-east, 10 is Calgary Trail and west, 12 is far south east, and 8 is Strathcona and east to the city limit. \n",
    "\n",
    "First try, we can isolate downtown from the surroundings.\n",
    "\n",
    "Note: I just googled a ward map. The ridings are changing for this current election - this data uses the old ridings, so I made sure I had an old map"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create new dataframe for Ward 6, and everything else from the non-garage set of homes."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plot the new groupings. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bingo, bango, we may have found what we are looking for! Our downtown condos have a peak that is lower than the surrounding areas (probably largely because they are older). With our above hypothesis, we can draw some conclusions. The distribution is a little bimodal, that might require some more in depth investigation. I suspect that the lower bump are properties on the beltline of central Edmonton, but we need to investigate to be sure. \n",
    "\n",
    "If central areas become more valuable as cities grow and densify, then looking at investing in downtown, non-garage properties may make some sense. They appear to be undervalued here compared to other subsets of property. \n",
    "\n",
    "This also gives us some evidence that the prices of our non-garage condos are not \"capped\". They follow a normalish distribution, so we shouldn't expect that their price hits a ceiling if we renovate or as areas gentrify. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#What percent of homes are 'cheap' in our different groups?\n",
    "#Create CDFs and caclulate the totals below some cutoff - I used $150k for mine. We could do a few. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 5: Investigate the location data a little further - examine what neighborhood these homes fall into. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#How many homes are in each hood?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#What is the average value of each set of hood's homes?"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Combo (sort of) view of the above tables. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Part 6: Look at one potential area - Glenora. There are a non trivial number of homes, and it appears that there are several homes that are \"underpriced\" compared to what we may typically expect. \n",
    "\n",
    "If there are cheap non-garage homes in a very nice and generally expensive hood, we might think that if we were to improve these homes and/or wait for the city to grow and densify, that the value of these homes may \"catch up\" to other homes in the area. Many people want to live in Glenora, but the large houses are appreciating away from the affordability of more and more people. This isn't a fact, it is a pretty reasonable hypothesis. If you have ever heard the saying \"buy the worst house on the block\", it follows the same logic - location matters over anythig else. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Extract the glenora homes into their own dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create dataframe with all the garaged homes in Glenora, so we can compare. "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plot Glenora's homes - garage vs none."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Take the satistics (note: the example up above of printing all the summary stats can be adapted here):"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, where are we? We have a hood where there are a non-trivial number of garge free homes, where the value of those homes is drastically lower than the overall average price in that hood. We also have a handfull of examples of expensive condos in that hood. We know this area is centrally located.\n",
    "\n",
    "From external knowledge, glenora is a desireable and wealthy hood overall. \n",
    "\n",
    "If we are going to look into actual investments, the limited dataset we have here supports us researching Glenora, specifically homes without garages in Glenora as a potential target. We can't be sure that this makes sense without going out anf getting more domain knowledge though - our data didn't have everything - square footage, building age, etc... that we'd need to put cash on the line. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f7dd21bfe8933d21e2c58a22bc74eff6eccb2180dc6c2e2695cf2d3822934f32"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}